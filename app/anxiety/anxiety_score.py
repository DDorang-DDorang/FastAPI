import os
import numpy as np
from pydub import AudioSegment
# import cv2 # ì‹œê°í™” í•¨ìˆ˜ ì‚¬ìš© ì‹œ í•„ìš”
from .voice_feature import extract_features_by_window
from .facial_feature import (
    extract_visual_features,
    analyze_blinks_from_ear_series,
    analyze_head_movement_spikes
    # , visualize_events_on_video # ì‹œê°í™” í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
)


def extract_audio_pydub(video_path, audio_path):
    try:
        print(f"--- 1. '{video_path}'ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹œì‘ (Pydub) ---")
        audio = AudioSegment.from_file(video_path, format="mp4")
        audio = audio.set_channels(1)
        audio.export(audio_path, format="wav")
        print(f"--- 1a. ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ ---")
        return True
    except Exception as e:
        print(f"Pydub ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def calculate_anxiety_scores(blinks, f0, jitter, shimmer, head_movement, is_audio_only=False):
    print("\n--- 3. ë¶ˆì•ˆ ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---")

    # --- ìœ íš¨ ë°ì´í„° í•„í„°ë§ ---
    valid_blinks = blinks[blinks > 0]
    valid_f0 = f0[f0 > 0]
    valid_jitter = jitter[jitter > 0]
    valid_shimmer = shimmer[shimmer > 0]
    valid_head = head_movement[head_movement > 0]

    # --- ì„ê³„ê°’ ê³„ì‚° (ìƒìœ„ 15%) ---
    blink_thresh = np.percentile(valid_blinks, 85) if len(valid_blinks) > 1 else 1
    f0_thresh = np.percentile(valid_f0, 85) if len(valid_f0) > 0 else 9999
    jitter_thresh = np.percentile(valid_jitter, 85) if len(valid_jitter) > 0 else 99
    shimmer_thresh = np.percentile(valid_shimmer, 85) if len(valid_shimmer) > 0 else 99
    head_thresh = np.percentile(valid_head, 85) if len(valid_head) > 1 else 1

    num_windows = len(blinks)
    blink_scores = np.zeros(num_windows)
    head_scores = np.zeros(num_windows)

    # ìŒì„± ì§€í‘œ ìŠ¤íŒŒì´í¬ ê³„ì‚°
    f0_spikes = (f0 >= f0_thresh).astype(float) * 2.0
    jitter_spikes = (jitter >= jitter_thresh).astype(float) * 1.5
    shimmer_spikes = (shimmer >= shimmer_thresh).astype(float) * 1.5

    for i in range(num_windows):
        if blinks[i] >= blink_thresh and blink_thresh > 0:
            score = max(1.0, min(2.0, blinks[i] / blink_thresh))
            blink_scores[i] = score * 1.0

        if head_movement[i] >= head_thresh and head_thresh > 0:
            score = max(1.0, min(2.0, head_movement[i] / head_thresh))
            head_scores[i] = score * 1.0

    # --- ì¹¨ë¬µ êµ¬ê°„ ì²˜ë¦¬ ---
    silent_mask = (f0 == 0)
    f0_spikes[silent_mask] = 0
    jitter_spikes[silent_mask] = 0
    shimmer_spikes[silent_mask] = 0

    # --- ë¶ˆì•ˆ ì ìˆ˜ í•©ì‚° ---
    anxiety_score_series = (
        blink_scores +
        f0_spikes +
        jitter_spikes +
        shimmer_spikes +
        head_scores
    )

    speaking_mask = (f0 > 0)
    speaking_anxiety_scores = anxiety_score_series[speaking_mask]

    if len(speaking_anxiety_scores) == 0:
        print("ê²½ê³ : ìŒì„± êµ¬ê°„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "N/A", "ìŒì„± êµ¬ê°„ ê°ì§€ ã„´", 0, anxiety_score_series, 0.0

    MAX_SCORE = 8.0 if not is_audio_only else 6.0
    average_score = np.mean(speaking_anxiety_scores)
    final_score_100 = (average_score / MAX_SCORE) * 100

    # --- (ìˆ˜ì •) ì˜¤ë””ì˜¤-onlyì¼ ê²½ìš° ì„ê³„ê°’ ë‚®ì¶¤ ---
    strong_threshold = 3.0 if is_audio_only else 4.5
    print(f"[ì„ê³„ê°’] ê°•í•œ ë¶ˆì•ˆ ê¸°ì¤€ = {strong_threshold}")

    strong_events_count = np.sum(speaking_anxiety_scores >= strong_threshold)
    strong_events_ratio = strong_events_count / len(speaking_anxiety_scores)

    grade, comment = get_anxiety_grade(strong_events_ratio)

    return grade, comment, final_score_100, anxiety_score_series, strong_events_ratio


# --- 3. ë¶ˆì•ˆ ë“±ê¸‰ ë³€í™˜ í•¨ìˆ˜ ---
# def get_anxiety_grade(score_100):
#     """(ìˆ˜ì •ë¨) 100ì  ë§Œì  ë¶ˆì•ˆ ì ìˆ˜ë¥¼ A-E ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜ (ì´ì  8.0 ê¸°ì¤€)"""
#     score_100 = max(0, min(100, score_100))
#     # Threshold ì˜ˆì‹œ (ì´ì ì´ ë†’ì•„ì¡Œìœ¼ë¯€ë¡œ ê¸°ì¤€ ì•½ê°„ ìƒí–¥ ë˜ëŠ” ìœ ì§€)
#     if score_100 >= 40: # ì˜ˆ: 45ì  ì´ìƒ (í‰ê·  3.6ì  ì´ìƒ)
#         return "E (ë§¤ìš° ë¶ˆì•ˆ)"
#     elif score_100 >= 30: # ì˜ˆ: 30ì  ì´ìƒ (í‰ê·  2.4ì  ì´ìƒ)
#         return "D (ë¶ˆì•ˆ)"
#     elif score_100 >= 20: # ì˜ˆ: 18ì  ì´ìƒ (í‰ê·  1.44ì  ì´ìƒ)
#         return "C (ì•½ê°„ ë¶ˆì•ˆ)"
#     elif score_100 >= 10:  # ì˜ˆ: 8ì  ì´ìƒ (í‰ê·  0.64ì  ì´ìƒ)
#         return "B (ì•ˆì •)"
#     else:
#         return "A (ë§¤ìš° ì•ˆì •)"
    
def get_anxiety_grade(density_ratio):
    density_ratio = max(0, min(1.0, density_ratio))
    
    if density_ratio >= 0.06:   
        return "E", "ë§¤ìš° ë¶ˆì•ˆ"
    elif density_ratio >= 0.05:
        return "D", "ë¶ˆì•ˆ"
    elif density_ratio >= 0.04: 
        return "C", "ì•½ê°„ ë¶ˆì•ˆ"
    elif density_ratio >= 0.03:
        return "B", "ì•ˆì •"
    else:                       
        return "A", "ë§¤ìš° ì•ˆì •"
    
def anxiety_analysis(video_file_path, audio_path, window_size=1.0):
    fps_from_video = 30
    is_audio_only = video_file_path.lower().endswith(".wav")

    try:
        f0_series, jitter_series, shimmer_series = extract_features_by_window(
            audio_path, window_size=window_size
        )

        if not is_audio_only:
            ear_series, head_movement_per_frame, fps_from_video = extract_visual_features(video_file_path)
            blink_series, _, _ = analyze_blinks_from_ear_series(ear_series, fps_from_video, window_size=window_size)
            head_spikes_series, _ = analyze_head_movement_spikes(head_movement_per_frame, fps_from_video, window_size=window_size)
        else:
            blink_series = np.zeros(len(f0_series))
            head_spikes_series = np.zeros(len(f0_series))

        min_len = min(len(f0_series), len(blink_series), len(head_spikes_series))
        result = calculate_anxiety_scores(
            blink_series[:min_len],
            f0_series[:min_len],
            jitter_series[:min_len],
            shimmer_series[:min_len],
            head_spikes_series[:min_len],
            is_audio_only=is_audio_only
        )

        return result

    except Exception as e:
        print(f"\n ë¶ˆì•ˆë„ ë¶„ì„ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    
# --- 4. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (â˜…ìˆ˜ì •ë¨â˜…) ---
if __name__ == "__main__":

    # --- ì„¤ì • ---
    VIDEO_FILE_PATH = "./sample_voices/FER_sample.mp4" # íŒŒì¼ ê²½ë¡œ í™•ì¸!
    WINDOW_SIZE = 1.0
    TEMP_AUDIO_PATH = "temp_audio_for_analysis.wav"

    fps_from_video = 30 # ê¸°ë³¸ê°’

    try:
        # --- [ë‹¨ê³„ 1] ì˜¤ë””ì˜¤ ì¶”ì¶œ ---
        extraction_success = extract_audio_pydub(VIDEO_FILE_PATH, TEMP_AUDIO_PATH)
        if not extraction_success:
            raise Exception("Pydub ì˜¤ë””ì˜¤ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        # --- [ë‹¨ê³„ 2~6] ë¶ˆì•ˆ ë¶„ì„ ìˆ˜í–‰ ---
        
        anxiety_grade, final_score, anxiety_series, strong_events_ratio = anxiety_analysis(
            VIDEO_FILE_PATH, TEMP_AUDIO_PATH, window_size=WINDOW_SIZE
        )

        # --- [ë‹¨ê³„ 5] ìµœì¢… ê²°ê³¼ ì¶œë ¥ (â˜…ìˆ˜ì •ë¨â˜…) ---
        print("\n--- ğŸ ìµœì¢… ë¶„ì„ ê²°ê³¼ ---")
        print(f"ì „ì²´ ë¶ˆì•ˆ ì§€ìˆ˜ (100ì  ë§Œì ): {final_score:.2f} ì ")
        print(f"ì¢…í•© ë¶ˆì•ˆ ë“±ê¸‰: {anxiety_grade}")
        print(f"ê°•í•œ ë¶ˆì•ˆ ë¹„ìœ¨: {strong_events_ratio:.5f} %")
        print()

        print("\n--- ì‹œê°„ëŒ€ë³„ ë¶ˆì•ˆ ì ìˆ˜ (0~8ì ) ---") # ìµœëŒ€ ì ìˆ˜ ë³€ê²½
        print(anxiety_series)

        # --- ì‹œê°„ëŒ€ë³„ ë¶ˆì•ˆ ì •ë³´ ì¶œë ¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---
        time = []
        severe_time = []
        for i in range(len(anxiety_series)) :
            # (â˜…ìˆ˜ì •â˜…) ê°•í•œ ë¶ˆì•ˆ ê¸°ì¤€ ì ìˆ˜ ë³€ê²½ (strong_threshold ê°’ê³¼ ì¼ì¹˜)
            if anxiety_series[i] >= 2.0 : # ì˜ˆ: 2ì  ì´ìƒ êµ¬ê°„ ê¸°ë¡
                # ì´ˆë¥¼ "ë¶„:ì´ˆ" í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (00:00)
                minutes = i // 60
                seconds = i % 60
                time_str = f"{minutes:02d}:{seconds:02d}"
                time.append(time_str)
                if anxiety_series[i] >= 4.5 : # ê°•í•œ ë¶ˆì•ˆ ê¸°ì¤€
                    severe_time.append(time_str)

        print("\nê°•í•œ ë¶ˆì•ˆ ê°ì§€ êµ¬ê°„ (4.5ì  ì´ìƒ):")
        print(severe_time if severe_time else "ì—†ìŒ")



    except Exception as e:
        print(f"\ní”„ë¡œì„¸ìŠ¤ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        # --- [ë‹¨ê³„ 7] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ ---
        if os.path.exists(TEMP_AUDIO_PATH):
            os.remove(TEMP_AUDIO_PATH)
            print(f"\nì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ '{TEMP_AUDIO_PATH}' ì‚­ì œ ì™„ë£Œ.")